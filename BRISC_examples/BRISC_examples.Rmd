---
title: "BRISC examples"
author: "Lukas Weber"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    number_sections: true
    toc_depth: 3
    toc_float:
      collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```


# Background

This document contains background and examples to illustrate the possible extensions to BRISC that we have been discussing.


## Spatial transcriptomics

We are interested in applying methods such as BRISC ([Saha and Datta 2018](https://onlinelibrary.wiley.com/doi/full/10.1002/sta4.184)) and GpGp ([Guinness 2018[(https://cran.r-project.org/web/packages/GpGp/index.html)]) to identify "spatially variable genes" in spatial transcriptomics data.

In spatial transcriptomics data, we are measuring transcriptome-wide gene expression (i.e. gene expression of all ~30,000 or so genes or transcripts in the human transcriptome) at a grid of approximately 5,000 spatial coordinates on a tissue slide. In the commercially available 10x Genomics Visium platform, the grid has dimensions approximately 6.5mm x 6.5mm, and the spatial coordinates ("spots") are located in a regular hexagonal grid.

The following figure illustrates the platform.

```{r, echo=FALSE, out.width="80%", fig.align="center", fig.cap="10x Genomics Visium schematic (from 10x Genomics website)."}
knitr::include_graphics("images/Visium.png")
```


## Spatially variable genes

The measurements from the Visium platform consist of sequencing read counts for the ~30,000 genes or transcripts at the ~5,000 spatial coordinates (spots), which are stored in a 30,000 x 5,000 counts matrix (note we usually store features in rows and observations in columns in Bioconductor, i.e. `p x n` instead of `n x p`). The matrix is highly sparse, due to non-detection of genes resulting from the sensitivity of the technology.

We then perform several initial preprocessing steps, including quality control and filtering, normalization to correct for biases such as different sequencing depth per spot, and log transformation to stabilize variance and transform to a continuous scale. These steps are fairly standard and are adapted from existing analysis pipelines for single-cell RNA sequencing data (although alternatives also exist, e.g. count-based models instead of log-transformation).

Next, we would like to identify a subset of "biologically informative" genes, or rank all genes by their biological information content and then take the top n% (e.g. top 10%). This is done to reduce noise (there are usually thousands of genes that are not related to any of the biological phenomena of interest in the dataset, so removing these tends to leave a clearer signal), and to improve computational scalability in later steps.

In the context of spatial transcriptomics, "biologically informative" means genes that have a spatially variable expression pattern across the tissue slide. For example, this could be related to spatial distributions of cell types, or spatial gradients of expression across the slide dimensions. These genes are referred to as "spatially variable genes" (SVGs), and we would like to identify them by either:

- identifying a set of statistically significant SVGs (with some assumptions on e.g. kernel and bandwidth), or 
- ranking all genes (e.g. by the estimated spatial variance component) and taking the top n% (e.g. top 10%)

In practice, this means we run a method such as BRISC once per gene (i.e. a loop over the 30,000 genes, or ~16,000 genes after filtering low-expressed genes) to estimate the significance of the spatial variance parameter (sigma squared) or compare the fitted model against a null model without spatial terms, and then rank genes by the resulting p-values. We can also calculate an effect size, e.g. the proportion of spatial variance (sigma_sq / (sigma_sq + tau_sq)).


## Existing methods

Existing methods for these types of analyses include:

- SpatialDE ([Svensson et al. 2018](https://www.nature.com/articles/nmeth.4636))
- SPARK ([Sun et al. 2020](https://www.nature.com/articles/s41592-019-0701-7))

However, both of these scale cubically in the number of spatial coordinates (spots). This means they can be used for earlier generations of the spatial transcriptomics platform (which had only a few hundred spots per slide), but cannot be used with the newer platform (5,000 spots per slide).

More recently, the following paper was published in June 2021:

- SPARK-X ([Zhu et al. 2021](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02404-0))

This method scales linearly with the number of spots and is extremely fast overall. However, in our initial evaluations, it does not work very well on our datasets in biological terms, i.e. the top-ranked genes do not look like true SVGs when we investigate them more closely. Specifically, it looks like the ranking of SVGs is driven by small numbers of outlier spots that are hard to control for -- however we are still investigating this more closely.


## BRISC and GpGp

The NNGP and Vecchia's approximation methods in BRISC and GpGp also allow us to fit models that scale linearly with the number of spots, and in our initial evaluations, give more sensible (i.e. biologically meaningful) final rankings of SVGs than SPARK-X.

Therefore, we would like to build a framework around BRISC for ranking SVGs in spatial transcriptomics datasets. In principle, this could be a simple parallelized wrapper function around BRISC, which runs BRISC once per gene and extracts the parameter estimates and other outputs. I have written an example function [here](https://github.com/lmweber/spatzli/blob/main/R/runSVGsBRISC.R), and a similar one for GpGp [here](https://github.com/lmweber/spatzli/blob/main/R/runSVGsGpGp.R).

Crucially, the linear scaling with the number of spots means that we can expect to continue to be able to apply these methods even with possible future generations of the spatial transcriptomics technology with even larger numbers of spots per tissue slide. Compared to the earlier generation of cubically scaling methods, this is a game-changer, and could potentially lead to wide adoption of these methods. Other than SPARK-X (which does not work very well on our datasets) and much simpler methods such as Moran's I or Geary's C (which we can use as a baseline comparison), we are not aware of any other methods to identify SVGs that scale linearly.


# BRISC extensions

In our initial work with BRISC, we have identified three possible extensions, which we think would be very useful for this project. The first two relate to computational scalability to run on thousands of genes, and the third is for approximate likelihood ratio tests.

Below I load some publicly available datasets and demonstrate some examples for these three ideas.


## Install packages

I will use the following packages from version 3.14 (the current `devel` version) of Bioconductor.

```{r, eval=FALSE}
# install Bioconductor 3.14
install.packages("BiocManager")
BiocManager::install(version = "3.14")

# Bioconductor packages
BiocManager::install("SpatialExperiment")
BiocManager::install("STexampleData")
BiocManager::install("scater")
BiocManager::install("scran")
```

I will also use GpGp and the following fork of BRISC. The only change in this BRISC fork is to output some additional runtimes.

```{r, eval=FALSE}
install.packages("GpGp")

# fork of BRISC
remotes::install_github("lmweber/BRISC")
```


## Load data and preprocessing

Here I load one of our publicly available example datasets, run several standard preprocessing steps to get it to the point where we can apply methods to identify SVGs, and then downsample to a few hundred genes (instead of 30,000) for the purposes of the examples in this document.

A complete workflow example of the preprocessing steps (and the subsequent downstream analysis steps) is available in one of our online resources [here](https://lmweber.org/OSTA-book/human-dlpfc-workflow.html).

This dataset measures gene expression in a small tissue sample of human brain from the dorsolateral prefrontal cortex (DLPFC) region, and was described in our publication [Maynard and Collado-Torres et al. 2021](https://www.nature.com/articles/s41593-020-00787-0).

```{r, message=FALSE}
library(SpatialExperiment)
library(STexampleData)
library(scater)
library(scran)
library(ggplot2)
library(dplyr)
library(tidyr)
```


```{r}
# load dataset as SpatialExperiment object from STexampleData package
spe <- Visium_humanDLPFC()

# dataset is stored in 'genes x spots' format
dim(spe)
# metadata describing features and observations
head(rowData(spe))
head(colData(spe))
head(spatialData(spe))
head(spatialCoords(spe))
# sparse matrix of sequencing read counts
counts(spe)[85:90, 1:6]
```


```{r, message=FALSE}
# run preprocessing steps

# subset to keep only spots overlapping with tissue
spe <- spe[, spatialData(spe)$in_tissue == 1]

# filter low-quality spots

# identify mitochondrial genes
is_mito <- grepl("(^MT-)|(^mt-)", rowData(spe)$gene_name)
# calculate per-spot QC metrics
spe <- addPerCellQC(spe, subsets = list(mito = is_mito))
# select QC thresholds
qc_lib_size <- colData(spe)$sum < 500
qc_detected <- colData(spe)$detected < 250
qc_mito <- colData(spe)$subsets_mito_percent > 30
qc_cell_count <- colData(spe)$cell_count > 12
# combined set of discarded spots
discard <- qc_lib_size | qc_detected | qc_mito | qc_cell_count
colData(spe)$discard <- discard
table(discard)

# remove low-quality spots
spe <- spe[, !colData(spe)$discard]

# normalization and log-transformation

# quick clustering for pool-based size factors
set.seed(123)
qclus <- quickCluster(spe)
# calculate size factors
spe <- computeSumFactors(spe, cluster = qclus)
# calculate logcounts (log-transformed normalized counts)
spe <- logNormCounts(spe)

# remove mitochondrial genes

# remove mitochondrial genes since these tend to be highly 
# expressed and not biologically informative
spe <- spe[!is_mito, ]
message("removing ", sum(is_mito), " mitochondrial genes out of total ", nrow(spe), " genes")
dim(spe)
```


Next, we filter genes with extremely low expression, which I have arbitrarily defined as less than or equal to 10 sequencing read counts ("unique molecular identifier" or UMI counts) across all spots combined. We also have a preprocessing function that performs some of these steps [here](https://github.com/lmweber/spatzli/blob/main/R/preprocessSVGs.R).

```{r}
# filter low-expressed genes
n_umi <- 10
sums <- rowSums(counts(spe))
ix_remove <- sums <= n_umi
message("removing ", sum(ix_remove), " out of ", nrow(spe), " genes due to low counts")
spe <- spe[!ix_remove, ]
dim(spe)
```


## Example plots and downsampling

Here, we can show some illustrative plots for some genes with known spatial expression patterns in this dataset. These plots show log-transformed normalized expression of each gene in the x-y coordinates of the tissue slide.

```{r, fig.width = 3.5, fig.height = 3}
# known interesting genes in this dataset
interesting <- c("MOBP", "SNAP25", "PCP4", "HBB", "IGKC", "NPY")

# generate plots
for (i in seq_along(interesting)) {
  gene <- interesting[i]
  ix_gene <- which(rowData(spe)$gene_name == gene)
  
  df <- as.data.frame(cbind(
    spatialCoords(spe), 
    logexpr = logcounts(spe)[ix_gene, ]
  ))
  
  p <- ggplot(df, aes(x = x, y = y, color = logexpr)) + 
    geom_point(size = 0.2) + 
    coord_fixed() + 
    scale_y_reverse() + 
    scale_color_gradient(low = "gray95", high = "blue") + 
    ggtitle(gene) + 
    theme_bw() + 
    theme(panel.grid = element_blank(), 
          axis.title = element_blank(), 
          axis.text = element_blank(), 
          axis.ticks = element_blank())
  
  print(p)
}
```


Finally, downsample the object to keep only a few hundred random genes, plus the known interesting genes from above. We do this only for computational scalability for the examples in this document, and would not normally do this in an analysis, since we are interested in ranking all genes that pass the filtering thresholds.

```{r}
# downsample to keep n random genes
n <- 200
set.seed(123)
ix_keep <- sample(seq_len(nrow(spe)), n)

# also keep known interesting genes
ix_interesting <- which(rowData(spe)$gene_name %in% interesting)
ix_keep <- c(ix_interesting, ix_keep)

spe <- spe[ix_keep, ]
dim(spe)
```


# Extension 1: Re-use sorting of coordinates

The first possible extension we have identified is to re-use the sorting of coordinates, which is performed in the initial steps in `BRISC_estimation()`.

In our setup, we fit ~16,000 models in a (parallelized) loop, with a different response vector for each of the ~16,000 genes, and the same grid of spatial coordinates (spots) each time.

From my understanding of the sorting schemes (as described by [Guinness 2018](https://arxiv.org/abs/1609.05372)), this means we could re-use the sorted coordinates in the loop iterations -- i.e. calculate the sorted coordinates once, and pass this as an input to a modified version of `BRISC_estimation()` in the loop instead of calculating it in each loop iteration. This could potentially save a huge amount of runtime in our loop.

Here I output some runtimes from `BRISC_estimation()` to estimate the amount of runtime we could save.

For this gene, sorting coordinates takes 1.8 seconds out of 2.8 seconds total.

```{r, message=FALSE}
library(BRISC)
```

```{r}
# response vector for a single gene
# i.e. 1 gene, 3582 spots overlapping with tissue
y_i <- logcounts(spe)[10, ]
length(y_i)

# scale coordinates proportionally
coords <- spatialCoords(spe)
range_all <- max(apply(coords, 2, function(col) diff(range(col))))
coords <- apply(coords, 2, function(col) (col - min(col)) / range_all)

# covariates
x <- NULL

# run BRISC to show runtimes
system.time({
  BRISC_estimation(coords = coords, y = y_i, x = x, 
                   n.neighbors = 15, order = "AMMD", 
                   cov.model = "exponential", search.type = "cb", 
                   verbose = TRUE)
})
```


# Extension 2: Re-use nearest neighbors

The second possible extension we have identified is to re-use the nearest neighbors.

The nearest neighbors are currently calculated internally in `BRISC_estimation()`, so in our loop setup they are re-calculated in each iteration. If it is possible to calculate the nearest neighbors once at the start and then pass this as an input in the loop iterations, this could potentially also save a large amount of runtime.

Here is an example using GpGp, which is slower overall but can be used to demonstrate these two options.

```{r, message=FALSE}
library(GpGp)
```

```{r}
# response vector for a single gene
# i.e. 1 gene, 3582 spots overlapping with tissue
y_i <- logcounts(spe)[10, ]
length(y_i)

# sort coordinates
coords <- spatialCoords(spe)
# calculate ordering only once
ord <- order_maxmin(coords)
# calculate nearest neighbors only once
nn <- find_ordered_nn(coords[ord, ], m = 15)

# covariates
x <- NULL

system.time({
  # note: using manual reordering, pre-calculated nearest neighbors
  fit_model(y = y_i[ord], locs = coords[ord, ], X = x[ord, ], 
            covfun_name = "exponential_isotropic", 
            NNarray = nn, reorder = FALSE, m_seq = 15, 
            silent = TRUE)
})
```


# Extension 3: Likelihood ratio tests

The third extension relates to approximate inference using likelihood ratio tests.

The main output we use to rank genes as SVGs is the estimated significance / p-value for the spatial variance parameter (`sigma.sq` in BRISC or `sigmasq` in GpGp). (We also use the estimated proportion of spatial variance as an effect size, i.e. `sigma.sq / (sigma.sq + tau.sq)` from BRISC or `sigmasq / (sigmasq + tausq)` from GpGp.)

Using the bootstrap inference from BRISC for 16,000 genes is quite slow in this case, so we have also investigated the use of a likelihood ratio test for approximate inference. This is similar to the approach used by one of the earlier methods for SVGs (SpatialDE, [Svensson et al. 2018](https://www.nature.com/articles/nmeth.4636)).

However, calculating the likelihood ratio tests requires us to obtain the fitted log-likelihoods for the models from each gene, so that we can calculate the deviance against a null model without spatial terms. From looking at the BRISC code, I think it is possible to extract this, but due to my inexperience with C++ / Rcpp I haven't been able to do this correctly yet.

As an example, using GpGp we can extract the fitted log-likelihoods as `loglik <- out$loglik`, and then calculate the likelihood ratio tests using `lm` to fit the non-spatial model. My code for this is in this function: https://github.com/lmweber/spatzli/blob/main/R/runSVGsGpGp.R

Here I do this for the 206 genes in our small object from earlier and using the function from above. (This takes ~3 minutes to run with 4 cores on my laptop.)

The outputs are stored in the `rowData()` slot (which contains features metadata such as gene IDs) in the `SpatialExperiment` object.

Then, we can rank genes by the p-values, which shows that the known genes with highly spatial expression patterns are highly significant, as expected.

```{r, eval=FALSE}
remotes::install_github("lmweber/spatzli")
```

```{r, message=FALSE}
library(spatzli)
```

```{r}
# fit GpGp models
runtime_gpgp <- system.time({
  spe_gpgp <- runSVGsGpGp(spe, x = NULL, n_threads = 4)
})

# runtime
runtime_gpgp

# calculate ranks according to p-values
rowData(spe_gpgp)$rank_gpgp_pval <- rank(rowData(spe_gpgp)$pval, ties.method = "first")
# calculate ranks according to effect sizes
rowData(spe_gpgp)$rank_gpgp_prop_sv <- rank(-1 * rowData(spe_gpgp)$prop_sv, ties.method = "first")
```

```{r}
# show output format
head(rowData(spe_gpgp))

# how many significant SVGs are detected? (using adjusted p-values)
table(rowData(spe_gpgp)$padj <= 0.05)

# how many "highly" significant SVGs?
table(rowData(spe_gpgp)$pval == 0)

# gene names for highly significant SVGs (note: includes the 6 known genes)
sig_genes <- rowData(spe_gpgp)$gene_name[rowData(spe_gpgp)$pval == 0]
sig_genes
```

```{r, fig.width=2.5, fig.height=2.5, dpi=48}
# plot expression for all highly significant SVGs to check if they look sensible
for (i in seq_along(sig_genes)) {
  gene <- sig_genes[i]
  ix_gene <- which(rowData(spe)$gene_name == gene)
  
  df <- as.data.frame(cbind(
    spatialCoords(spe), 
    logexpr = logcounts(spe)[ix_gene, ]
  ))
  
  p <- ggplot(df, aes(x = x, y = y, color = logexpr)) + 
    geom_point(size = 0.1) + 
    coord_fixed() + 
    scale_y_reverse() + 
    scale_color_gradient(low = "gray95", high = "blue") + 
    ggtitle(gene) + 
    theme_bw() + 
    theme(panel.grid = element_blank(), 
          axis.title = element_blank(), 
          axis.text = element_blank(), 
          axis.ticks = element_blank())
  
  print(p)
}
```


# Possible future ideas

## Faster / multivariate bootstrap inference?

Currently, we can use both bootstrap inference from BRISC and likelihood ratio (LR) tests from GpGp, where we are using the LR tests from GpGp as a fast approximation. The runtime for the full loop over 16,000 genes using GpGp for the LR tests is approximately 5 hours with 4 cores on my laptop. If we can use BRISC for the LR tests instead, we expect this will be faster.

However, would it somehow also be possible to perform the bootstrap inference in a faster setup instead of using our loop? e.g. some sort of multivariate bootstrapping using the full multivariate response for all 16,000 genes (16,000 genes measured at 3,500 spatial coordinates). I'm not sure if this makes sense (since we want to estimate the spatial variance parameter separately for each gene), but would be extremely useful if it is somehow possible.


## Fix bandwidth (or other) parameters?

Would it be biologically meaningful to fix the bandwidth parameter in the kernel? i.e. the `phi` parameter in BRISC, or the `range` parameter in GpGp. This is not currently possible in BRISC, but can be done in GpGp. However, when I tried it out, it did not give a biologically sensible final ranking of genes.

From a biological perspective, I am not sure we really want to do this, since we are interested in ranking genes according to the strength of *any* spatial patterns of expression, which may be correlated with different tissue structures for different genes. However, it is possible that this could make sense in different datasets that we have not looked at yet.


# Session info

```{r}
sessionInfo()
```

